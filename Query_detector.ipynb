{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/cFGrWg3T+pdAPu+ETBgq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayameena832/Query-Engine-for-English-language./blob/main/Query_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from qdrant_client import QdrantClient\n",
        "import tensorflow as tf\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "# Load the BigBasket's Products List data\n",
        "products_df = pd.read_csv('/content/bigBasketProducts.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "products_df['description_lower'] = products_df['description'].str.lower()\n",
        "products_df['description_tokenized'] = products_df['description_lower'].str.split()"
      ],
      "metadata": {
        "id": "Hsukf3Ro_udk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = products_df['description_tokenized'].isnull().sum()\n",
        "if missing_values > 0:\n",
        "    # Handle missing values (fill or remove)\n",
        "    products_df['description_tokenized'].fillna('', inplace=True)  # Filling with an empty string for illustration\n",
        "\n",
        "# Ensure 'description' column contains only strings\n",
        "products_df['description_tokenized'] = products_df['description_tokenized'].astype(str)\n"
      ],
      "metadata": {
        "id": "18zsjTV7A5c5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the product descriptions using Word2Vec\n",
        "word2vec_model = Word2Vec(products_df['description_tokenized'], vector_size=128, min_count=5, window=5)\n",
        "product_vectors = []\n",
        "for description_tokenized in products_df['description_tokenized']:\n",
        "    product_vector = np.zeros(128)\n",
        "    for token in description_tokenized:\n",
        "        try:\n",
        "            product_vector += word2vec_model.wv[token]\n",
        "        except KeyError:\n",
        "            pass\n",
        "    product_vector /= len(description_tokenized)\n",
        "    product_vectors.append(product_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xttO7BYd_uaI",
        "outputId": "9457aa72-5e4d-43e3-8c6e-c2d4f4293816"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "<ipython-input-24-b73b2b0f923a>:11: RuntimeWarning: invalid value encountered in divide\n",
            "  product_vector /= len(description_tokenized)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import AsyncQdrantClient, models"
      ],
      "metadata": {
        "id": "blWsJqmNDCeO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the vectorized product descriptions in Qdrant\n",
        "qdrant_client = Client()\n",
        "qdrant_client.create_collection('products', vectors=product_vectors)"
      ],
      "metadata": {
        "id": "FoSdflT5CDd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a Language Model using TensorFlow\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(10000, 128),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.Dense(128, activation='tanh'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(products_df['description_tokenized'].tolist(), products_df['price'].tolist(), epochs=10)"
      ],
      "metadata": {
        "id": "FmL6sIv6Af4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap the LLM as an API using Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query_products():\n",
        "    query = request.json['query']\n",
        "    # Parse the natural language query into meaningful instructions for the LLM\n",
        "    # Use the LLM model to generate a contextual response\n",
        "    response = model.predict(query)\n",
        "    return jsonify({'response': response})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "DyJhGVnoHAx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}